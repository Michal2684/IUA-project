{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3e3052-651a-48c8-91e7-d6e2485837de",
   "metadata": {},
   "source": [
    "# Phase 1 – Exploratory Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560e6b5-c36d-497f-a847-aad842eca44f",
   "metadata": {},
   "source": [
    "## 1.1 Basic Data Description and Characteristics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7423c-8d5f-4bcf-971d-b105296c5f4e",
   "metadata": {},
   "source": [
    "# A)\n",
    "\n",
    "| **Dataset** | **Number of Records** | **Number of Attributes** | **Main collums** | **Description** |\n",
    "|--------------|------------------------|----------------------------|-----------------|-----------------|\n",
    "| **patient.csv** | 2,068 | 13 |username, registration, address, ssn, residence, birthdate, sex, age, bmi, height, weight, diagnosis, treatment| Contains patient information – demographic data (age, sex, address) and basic clinical characteristics (BMI, diagnosis, treatment). |\n",
    "| **station.csv** | 832 | 6 |station, latitude, revision, longitude, code, location|  Data about individual measurement stations – GPS coordinates, station code, name, and hardware revision. |\n",
    "| **observation.csv** | 12,046 | 23 | SpO₂, HR, PI, RR, EtCO₂, FiO₂, PRV, BP, Skin Temp, Core Temp, O₂Flow, pH, PaO₂, PaCO₂, Na⁺, K⁺, Ca²⁺, Hb, Hct, Glu, Lac, patient, station| Records of patient vital parameter measurements, including oxygen saturation (SpO₂), heart rate, respiratory rate, and other biochemical indicators. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed3e97c-362c-4a7d-95d0-213e1f182c06",
   "metadata": {},
   "source": [
    "In total, the patient.csv file contains 2,068 patients, all of whom have a valid station_ID referencing one of the 832 stations listed in station.csv (IDs range from 0 to 831).\n",
    "The observation.csv table includes 12,046 measurements, and 100 % of them can be matched to a corresponding station using identical latitude and longitude coordinates.\n",
    "This means that every patient and every observation can be correctly linked to its station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688cd94-18ec-4122-9eca-295d5df8cc9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T18:50:27.356687Z",
     "start_time": "2025-10-26T18:50:24.466586Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.impute import KNNImputer\n",
    "import statsmodels.stats as sm_stats\n",
    "import statsmodels.api as sm\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\" \n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bf042-c968-4bec-bbb6-2fd2b654ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_any(path):\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=None, engine=\"python\", encoding=\"utf-8-sig\")\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, sep=\";\", engine=\"python\", encoding=\"utf-8-sig\")\n",
    "\n",
    "patient = read_any(\"data/patient.csv\")\n",
    "station = read_any(\"data/station.csv\")\n",
    "observation = read_any(\"data/observation.csv\")\n",
    "sensor_range = read_any(\"data/sensor_variable_range.csv\")\n",
    "\n",
    "(len(patient), len(station), len(observation), len(sensor_range))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d54d4-d2c4-4ac2-8dd9-5fd723078fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_profile(df, name):\n",
    "    print(f\"\\n================================= {name} =================================\")\n",
    "    print(f\"Rows: {len(df):,} | Columns: {len(df.columns)}\")\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "    print(\"\\nData types:\")\n",
    "    display(df.dtypes.to_frame(\"dtype\"))\n",
    "    print(\"\\nMissing values per column (top 10):\")\n",
    "    display(df.isna().sum().sort_values(ascending=False).head(10))\n",
    "    print(\"\\nSample rows:\")\n",
    "    display(df.head(5))\n",
    "\n",
    "quick_profile(patient, \"patient\")\n",
    "quick_profile(station, \"station\")\n",
    "quick_profile(observation, \"observation\")\n",
    "quick_profile(sensor_range, \"sensor_variable_range\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca85a6e-d1cc-4615-b377-c3430d31a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"station_ID\" in patient.columns:\n",
    "    sid = pd.to_numeric(patient[\"station_ID\"], errors=\"coerce\").dropna().astype(int)\n",
    "    print(\"patient.station_ID range:\", int(sid.min()), \"to\", int(sid.max()), \"| station rows:\", len(station))\n",
    "\n",
    "if {\"latitude\",\"longitude\"}.issubset(observation.columns) and {\"latitude\",\"longitude\"}.issubset(station.columns):\n",
    "    st_pairs = set(zip(pd.to_numeric(station[\"latitude\"], errors=\"coerce\").round(6), pd.to_numeric(station[\"longitude\"], errors=\"coerce\").round(6)))\n",
    "    obs_pairs = list(zip(pd.to_numeric(observation[\"latitude\"], errors=\"coerce\").round(6), pd.to_numeric(observation[\"longitude\"], errors=\"coerce\").round(6)))\n",
    "    mapped = sum(1 for p in obs_pairs if p in st_pairs)\n",
    "    print(f\"Observations with a station coordinate match: {mapped:,} / {len(obs_pairs):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a3d021-d1d0-47cf-afe2-fe087209f72d",
   "metadata": {},
   "source": [
    "# B)\n",
    "\n",
    "We analyzed 12 numeric attributes from observation.csv (SpO₂, HR, PI, RR, EtCO₂, FiO₂, PRV, Skin Temperature, PVI, Hb level, SV, CO). For each attribute, we computed descriptive statistics and compared values against the prescribed ranges from sensor_variable_range.csv. Across 12,046 observations per attribute, there were no missing values and 0% of values fell outside the expected ranges. Min–max values for each attribute matched the stated bounds, indicating full compliance.\n",
    "Distributions were visualized with histograms and boxplots. The alignment with ranges suggests that the dataset is potentially normalized to those limits (evidence: min and max equal the exact bounds for all variables). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341ddae-e728-4dce-a04a-fa36b900857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [\"SpO₂\", \"HR\", \"PI\", \"RR\", \"EtCO₂\", \"FiO₂\", \"PRV\", \"Skin Temperature\", \"PVI\", \"Hb level\", \"SV\", \"CO\"]\n",
    "vars_to_check = [c for c in candidates if c in observation.columns]\n",
    "observation_subset = observation[vars_to_check]\n",
    "observation_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c6e6f-b962-4805-aa46-83cbbe0bd2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_num = observation[vars_to_check].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "desc = obs_num.describe().T \n",
    "desc[\"missing\"] = obs_num.isna().sum()\n",
    "desc[\"non_null\"] = obs_num.notna().sum()\n",
    "desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de52175-ea6b-4579-b4ca-94b9755bbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in vars_to_check:\n",
    "    s = pd.to_numeric(observation[col], errors=\"coerce\").dropna()\n",
    "    if s.empty:\n",
    "        print(f\"[{col}] No numeric data.\")\n",
    "        continue\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(s, bins=30)\n",
    "    plt.title(f\"Histogram — {col}\")\n",
    "    plt.xlabel(\"Value\"); plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.boxplot(s, vert=True)\n",
    "    plt.title(f\"Boxplot — {col}\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5eae7d-ab4b-4836-ae1c-6b3af3997bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def check_ranges(row):\n",
    "    var = row['Variable']\n",
    "    rng = row['Value Range']\n",
    "\n",
    "    if not isinstance(var, str) or var not in obs_num.columns or not isinstance(rng, str):\n",
    "        return None\n",
    "\n",
    "    m = re.search(r'(-?\\d+(?:\\.\\d+)?)\\s*[-–—]\\s*(-?\\d+(?:\\.\\d+)?)', rng)\n",
    "    if not m:\n",
    "        return None\n",
    "\n",
    "    lo, hi = float(m.group(1)), float(m.group(2))\n",
    "\n",
    "    s = obs_num[var].dropna()\n",
    "    if s.empty:\n",
    "        return None\n",
    "\n",
    "    below = int((s < lo).sum())\n",
    "    above = int((s > hi).sum())\n",
    "    total = int(s.size)\n",
    "    return {\n",
    "        'variable': var, 'expected_low': lo, 'expected_high': hi,\n",
    "        'values_checked': total, 'below_range': below, 'above_range': above,\n",
    "        'outside_%': round(100 * (below + above) / total, 2)\n",
    "    }\n",
    "\n",
    "results = sensor_range.apply(check_ranges, axis=1).dropna()\n",
    "pd.DataFrame(results.tolist()).sort_values('outside_%', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f34d0f-e258-49dc-aec5-2cfc7a5f7070",
   "metadata": {},
   "source": [
    "# C\n",
    "\n",
    "In the heatmap, besides predominantly weak correlations, there is a negative correlation between Skin Temperature and BP (Blood Pressure).\n",
    "This means that when the skin temperature increases, blood pressure tends to decrease.\n",
    "From a modeling perspective, it indicates that these two variables are not completely independent and may share a common underlying factor, such as the body’s thermoregulatory response.\n",
    "The heatmap also reveals a strong positive correlation around 0.7 between Oximetry and EtCO₂. Both variables describe related aspects of respiratory function, which explains their close relationship.\n",
    "They may carry overlapping information and should be treated as correlated predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a9148-0eb9-4f97-8aad-544f48d06d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "num_df = observation.select_dtypes(include=\"number\")\n",
    "\n",
    "corr = num_df.corr()\n",
    "\n",
    "corr_pairs = (\n",
    "    corr.unstack()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"Variable 1\", \"level_1\": \"Variable 2\", 0: \"r\"})\n",
    ")\n",
    "corr_pairs = corr_pairs[corr_pairs[\"Variable 1\"] < corr_pairs[\"Variable 2\"]]  \n",
    "corr_pairs[\"abs_r\"] = corr_pairs[\"r\"].abs()\n",
    "corr_pairs.sort_values(\"abs_r\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa4763-e01a-4388-89f5-21f6711a91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Correlation heatmap of numeric attributes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402744e7-e96c-41e5-a2e3-b6d01327dcfd",
   "metadata": {},
   "source": [
    "# D\n",
    "The correlation analysis between the target variable oximetry and all numeric predictors reveals that most correlation coefficients are relatively low, suggesting weak linear relationships.\n",
    "The strongest positive correlations are observed for EtCO₂ around 0.66, Skin Temperature around 0.37, and Respiratory Rate around 0.29, indicating that higher values of these variables tend to be associated with a higher probability of critical oxygen saturation.\n",
    "In contrast, weak negative correlations are found for BP, FiO₂, and Respiratory effort, implying an inverse relationship with the oximetry outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb90281-315f-46bb-a4e6-6981aba227f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"oximetry\"\n",
    "predictors = [v for v in num_df.columns if v != target]\n",
    "\n",
    "target_corr = num_df[predictors + [target]].corr()[target].drop(target).sort_values(ascending=False)\n",
    "target_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e1f39-e500-44a1-9456-566967b81534",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "target_corr.plot(kind=\"bar\", color=\"steelblue\")\n",
    "plt.title(\"Correlation of predictors with oximetry (target variable)\")\n",
    "plt.ylabel(\"Correlation coefficient (r)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d0f26-3abf-47c8-8518-455de45e6b53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# E\n",
    "\n",
    "**Are some attributes dependent on each other?**\n",
    "\n",
    "Most pairs of numerical attributes show weak linear correlations (the heatmap is mostly light blue).\n",
    "\n",
    "Notable exceptions:\n",
    "- Skin Temperature <-> BP: a negative correlation, meaning higher skin temperature is associated with lower blood pressure.\n",
    "- Oximetry <-> EtCO₂: a strong positive correlation around 0.7, as both describe aspects of respiratory function and may carry overlapping informations.\n",
    "\n",
    "There is no critical multicollinearity among all sensors, but certain pairs are related and should be handled carefully in modeling.\n",
    "\n",
    "**Which attributes does the predicted variable depend on? (oximetry)**\n",
    "\n",
    "The correlations between oximetry and other numeric predictors show that:\n",
    "- EtCO₂, Skin Temperature, and Respiratory Rate (RR) exhibit the strongest positive associations, suggesting that higher values of these features increase the likelihood of a critical oxygen saturation event.\n",
    "- On the other hand, BP, FiO₂, and Respiratory effort show weak negative correlations.\n",
    "Overall, oxygen saturation seems to depend on many different factors working together, not just one variable\n",
    "\n",
    "**Is it necessary to combine records from multiple files?**\n",
    "\n",
    "Yes, merging the datasets increases the information content and context for analysis:\n",
    "- observation – contains the primary physiological measurements.\n",
    "- station – adds contextual information.\n",
    "- patient – provides patient characteristics.\n",
    "\n",
    "Practically, the datasets should be joined via shared keys like station_ID, patient_id, and derived features like is_out_of_range, deviations, time-based aggregations can be added.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a51fe2-6b95-4a51-9b24-942524edf4e1",
   "metadata": {},
   "source": [
    "# 1.2 Problem identification, data integration and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d8136-dc00-4951-a21e-33ca47aec52d",
   "metadata": {},
   "source": [
    "# A)\n",
    "\n",
    "**Data structure and relationships**\n",
    "\n",
    "All files were successfully imported in CSV format with UTF-8-SIG encoding, preventing problems with special characters or accents. Column names contained occasional extra spaces or inconsistent dash symbols (\"–\", \"—\", \"-\"), which were standardized.\n",
    "\n",
    "The relationships between tables were verified:\n",
    "- patient.station_ID correctly links to stations in station.csv.\n",
    "- observation records can be matched to stations using geographical coordinates (latitude, longitude).\n",
    "\n",
    "The overall structure is coherent and ready for integration.\n",
    "\n",
    "**Missing or incomplete values**\n",
    "\n",
    "Several numeric columns contain missing (NaN) or zero-like placeholder values.\n",
    "\n",
    "**Duplicate records**\n",
    "\n",
    "The dataset was tested for duplicate rows using the df.duplicated().sum() function. No duplicate entries were found in any of the files.\n",
    "\n",
    "**Inconsistent data formats**\n",
    "\n",
    "Some numeric variables are stored as strings or contain non-numeric symbols, they were converted to proper numeric types using pd.to_numeric(errors=\"coerce\"). Text columns containing names, addresses, or codes were kept as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d53693-ae7b-428e-8809-629d395cf851",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_check = pd.DataFrame({\n",
    "    \"Dataset\": [\"patient\", \"station\", \"observation\"],\n",
    "    \"Duplicate Rows\": [\n",
    "        patient.duplicated().sum(),\n",
    "        station.duplicated().sum(),\n",
    "        observation.duplicated().sum()\n",
    "    ]\n",
    "})\n",
    "dup_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf650ac3-c603-4595-a8e6-8f4438190e5c",
   "metadata": {},
   "source": [
    "# B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43650213-821a-48d9-aa99-5f4042bf8bf1",
   "metadata": {},
   "source": [
    "**Abnormal Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ccfcd-103f-4de4-b88f-5e8ee5a3b367",
   "metadata": {},
   "source": [
    "In out project, we can consider abnormal values those that does not fall in the expected ranges. We have already checked that all our important variables values fall in the expected ranges in section 1.1 B), where we saw that 0% of values of each column fall outside. Thus, the data has not abnormal values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d52b7b5-29c0-4ee6-8843-07da018fe8c9",
   "metadata": {},
   "source": [
    "**Illogical data relationships (Data collection and annotation proess)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fabe98d-5581-446d-b576-9a7d8639ad34",
   "metadata": {},
   "source": [
    "In this part, we'll verify if the data collection and annotation process had an effect over our dataset by checking some cientific relations that the dataset should satisfy. The first thing to take into account is the absence of abnormal values, which can cause illogical relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d037d-f39b-44d7-b2ea-26cd3e545d0d",
   "metadata": {},
   "source": [
    "--1st Verification CO = HR x SV /100 --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1f029-cd14-49b6-958c-e6ebe6410ba9",
   "metadata": {},
   "source": [
    "The first thing we want to check is if our records satisfy CO = HRxSV/100. This is the Cardiac Output Formula that states that Cardiac Output is given by a product of Heart Rate and Stroke Volume (divided by 1000 to match units).\n",
    "We'll check how many rows of observation.csv does not satisfy this equation by giving a tolerance. In this case we'll consider and incoherence if the value differs by 30% of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ca3b1-27c8-4a79-97ef-66f3512c9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_est = observation[\"HR\"] * observation[\"SV\"] / 1000\n",
    "CO_diff = np.abs(observation[\"CO\"] - CO_est) / CO_est\n",
    "inconsistent_CO = observation[CO_diff > 0.3]\n",
    "print(f\"Number of incoherent rows CO-HR-SV: {len(inconsistent_CO)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49844416-3a56-4f43-be3e-ba610e5e627b",
   "metadata": {},
   "source": [
    "We can see that there are so many rows that can be considered as an incoherence in this case. This quantity of rows decreases if we increase the tolerance. This can be considered as an illogical data relationship given by the data collection and annotation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548669f-1e14-4878-9fde-e961c0d35a24",
   "metadata": {},
   "source": [
    "---2nd Verification: Correlation between FiO2 and SpO2--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e8ad7-61fb-48d5-8a66-b2f63069a260",
   "metadata": {},
   "source": [
    "In this case, we want to check if our dataset has a high value on SpO2 (Periferic saturation of oxygen) when FiO2(Fraction of oxygen inspired) is high. This should be true becuase when someone inhales a great percentatge of oxygen, the percentatge of hemoglobin in the oxygen shoulg be high as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60481b-4b10-47b2-a0b9-c6b9c9369b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_fio2_spo2 = observation[(observation[\"FiO₂\"] > 80) & (observation[\"SpO₂\"] < 85)]\n",
    "print(f\"Incoherent Cases FiO₂-SpO₂: {len(weird_fio2_spo2)}\")\n",
    "\n",
    "sns.scatterplot(data=observation, x=\"FiO₂\", y=\"SpO₂\")\n",
    "plt.title(\"FiO₂ vs SpO₂\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa09d6a-0cc5-46e5-9061-b10c674cbe31",
   "metadata": {},
   "source": [
    "In this case we could not find any incoherent value, all rows stay high on SpO2 if FiO2 is high. As we can see in the scatterplot, no rows have FiO2 higher than 80 while having a SpO2 value lower than 95."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6de3d-0048-4148-aca2-21747df77138",
   "metadata": {},
   "source": [
    "--Verificacion 3: EtCO2 and SpO2 relation--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b21ec-58f5-45f5-9c31-fe72c46598b1",
   "metadata": {},
   "source": [
    "This time, we expect some neutral correlation or a weakly positive one beacause if a decrease of EtCO2 should come along with a decrease of SpO2. The reason beyond that is that the periferic saturation of O2 should follow the partial pressure of CO2 at the end of the exhale behaviour in most of the cases. If not, this should be considered and incoherence. Thus, we'll check its correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c90e2-8223-41d5-b60e-8ebc0dc78427",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_etco2_spo2 = observation[\"EtCO₂\"].corr(observation[\"SpO₂\"])\n",
    "print(f\"Correlación EtCO₂–SpO₂: {corr_etco2_spo2:.3f}\")\n",
    "\n",
    "sns.scatterplot(data=observation, x=\"EtCO₂\", y=\"SpO₂\")\n",
    "plt.title(\"EtCO₂ vs SpO₂\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642213a6-e691-41aa-845c-783fc3dd6b3f",
   "metadata": {},
   "source": [
    "The correlation is weakly positive, so there is no incoherence here. This can be seen in the scatterplot, where we can see that rows are distributed all over the space with no relation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9213a66-99fe-409c-91d0-cb92bf23de8d",
   "metadata": {},
   "source": [
    "--Verification 4: HR and RR Relation--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42e839-ed34-4ebe-b63d-8cede254e321",
   "metadata": {},
   "source": [
    "Here we are comparing Heart Rate with Respiration Rate. What we are looking for here is a moderate positive correlation because HR and RR should be sincronized. For example, if someone is stressed or doing sport, both tend to increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c75d04-35aa-4d40-a0bf-d04c2a1c58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_hr_rr = observation[\"HR\"].corr(observation[\"RR\"])\n",
    "print(f\"Correlación HR–RR: {corr_hr_rr:.3f}\")\n",
    "\n",
    "sns.scatterplot(data=observation, x=\"RR\", y=\"HR\")\n",
    "plt.title(\"HR vs RR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a88c1-d755-481a-b1e0-4a759a4d3c4f",
   "metadata": {},
   "source": [
    "The correlation is positive, but not as positive as we could think about. This can be considered as a slight incoherence because correlation should be at least > 0.2. In the scatter, we can guess some pattern in the right top corner, which relates and increase in HR with an increase in HR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a888cf-28df-4f2a-a073-a2117eceb660",
   "metadata": {},
   "source": [
    "--Verification 5: Skin Temperature vs Blood Flow Index--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c56d17-7ce3-45a3-ac2c-bfbb898ebdb1",
   "metadata": {},
   "source": [
    "If someone has higher Blood Flow Index, he should have a higher skin temperature as well, because more heat is carried in the veins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f46e9-ae76-4e87-afa7-774c71677684",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_temp_flow = observation[\"Skin Temperature\"].corr(observation[\"Blood Flow Index\"])\n",
    "print(f\"Correlación Skin Temperature–Blood Flow Index: {corr_temp_flow:.3f}\")\n",
    "\n",
    "sns.scatterplot(data=observation, x=\"Blood Flow Index\", y=\"Skin Temperature\")\n",
    "plt.title(\"Temperatura de piel vs Índice de flujo sanguíneo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885e46f-d41a-450c-89c8-8c7c5cee9d08",
   "metadata": {},
   "source": [
    "Although the scatterplot ssuggest some sort of neutral relation, correlation is weakly negative. This is another incoherence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c2954-9b01-4445-a170-af07349fc225",
   "metadata": {},
   "source": [
    "----Verification 6: SpO2 and O2 extraction ratio relation---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d951b851-ce04-4be0-9480-2e2dac41149d",
   "metadata": {},
   "source": [
    "Out last check is SpO2 and O2 relation. Correlation should be negative because oxygen extraction should be low if arterial saturation (SpO2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf06a7f-1ae9-4863-99a9-02c6626a1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_spo2_o2ext = observation[\"SpO₂\"].corr(observation[\"O₂ extraction ratio\"])\n",
    "print(f\"Correlación SpO₂–O₂ extraction ratio: {corr_spo2_o2ext:.3f}\")\n",
    "\n",
    "sns.scatterplot(data=observation, x=\"SpO₂\", y=\"O₂ extraction ratio\")\n",
    "plt.title(\"SpO₂ vs O₂ extraction ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b20d04d-1ec0-46aa-a41a-531771962388",
   "metadata": {},
   "source": [
    "Here we have found our last incoherence. Correlation is close to be neutral, as the scatterplot shows as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a14599-475d-4d14-94d4-28f5fd93041f",
   "metadata": {},
   "source": [
    "To sum up we have found some incoherences product of the annotation process, which made observations not to satisfy medical and cientific relations. Those are the following:\n",
    "\n",
    "    - CO = HR*SV/1000 is not satisfied in a lot of rows \n",
    "    - HR is not as high positevely correlated with RR as it is expected\n",
    "    - Skin Temperature is not positevly correlated with Blood Flow Index as should be\n",
    "    - SpO2 and O2 are not negatively correlated.\n",
    "\n",
    "This incoherences are due to the impresition of sensors and should be a warning for our study, but not an impediment. We'll continue with our project taking this into account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674160b-5081-4937-8760-d7469239497f",
   "metadata": {},
   "source": [
    "# C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3196b-2510-4032-a8f5-fe0d225a2f4c",
   "metadata": {},
   "source": [
    "In this section we are going to deal with outliers. So, at first, we have to detect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339aefd-1c5c-400d-a4a9-ff6b5f8dfa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = observation.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "observation[num_cols].boxplot(rot=90)\n",
    "plt.title(\"Boxplots of numerical values\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428501f-62ec-4d63-8031-41a611bc8d94",
   "metadata": {},
   "source": [
    "We can see by looking at the boxplots that there are outliers (black dots). To adress them, we'll use the Interquartile Range method (IQR), i.e, identify as outlier those much smaller than Q1 (25th percentile) ot those much larger than Q3 (75th percentile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58bf27-e26c-48c2-8d7c-41407e75daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(a):\n",
    "    lower = a.quantile(0.25) - 1.5 * stats.iqr(a)\n",
    "    upper = a.quantile(0.75) + 1.5 * stats.iqr(a)\n",
    "    \n",
    "    return a[(a > upper) | (a < lower)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f117ef-0a07-4464-bda1-c9decb2cf727",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in observation.columns:\n",
    "    print(f'Outliers from {column}: {len(identify_outliers(observation[column]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4432da-9854-4e2b-89e1-d5aadcc222c0",
   "metadata": {},
   "source": [
    "Here we see the number of outliers from each column. We can separate them in four groups based on the percentatge of rows that have outliers.\n",
    "\n",
    "    - Without Outliers: EtCO2, BP, O2, extraction ratio, SNR, Oximetry, Longitude\n",
    "    - Few number of outliers (<1%): SpO2, PI, RR, PRV, Skin Temp, Motion/Activity Index,  PVI, Hb, SV, Blood Flow Index, PPG waveform features, Signal Quality Index, Respiratory effort.\n",
    "    - Moderate number of outliers (1-3%): HR, FiO2, Latitude\n",
    "    - High number of outliers(11%): CO\n",
    "\n",
    "This is really important to take into account because dpending the percentatge of outliers we should treat them in a way or another. For example, we can't get rid of CO outliers because we would eliminate 11% of out data. In the moderate cases, we also should think of another moethod but eliminating them is not critical. In the few outliers case, we could eliminate them with much problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a229e-ff97-4a11-8c19-6426e467608f",
   "metadata": {},
   "source": [
    "First, we are going to eliminate outliers on those variables who have a few of them. Before doing it, we'll check if it is beneficial for out study by looking at the distribution of those variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886d8f4-0489-40fe-9ca6-e57585c12b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return series[(series >= lower) & (series <= upper)]\n",
    "\n",
    "\n",
    "low_outlier_columns = [\"SpO₂\",\"PI\",\"RR\",\"PRV\",\"Skin Temperature\",\"Motion/Activity index\",\"PVI\",\"Hb level\",\"SV\",\"Blood Flow Index\", \"PPG waveform features\",\"Signal Quality Index\", \"Respiratory effort\"]\n",
    "for column in low_outlier_columns:\n",
    "    data = observation[column]\n",
    "    data_without_outliers = remove_outliers_iqr(data)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    fig.suptitle(f\"{column} Distribution - Before vs After outliers\", fontsize=14, fontweight='bold')\n",
    "\n",
    "    sns.histplot(data, bins=30, kde=True, ax=axes[0], color='steelblue')\n",
    "    axes[0].set_title(\"Before outliers\")\n",
    "    axes[0].set_xlabel(column)\n",
    "    axes[0].set_ylabel(\"\")\n",
    "\n",
    "    sns.histplot(data_without_outliers, bins=30, kde=True, ax=axes[1], color='seagreen')\n",
    "    axes[1].set_title(\"After outliers\")\n",
    "    axes[1].set_xlabel(column)\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ce337-dc40-4b66-b937-f0de81b8b3d6",
   "metadata": {},
   "source": [
    "By looking at variable distribution, we can see how outliers affect them. In most cases, deleting outliers allows variables to avoid those extreme values and resemble better a normal distribution. This is beneficial beause those long cues can affect out tests in the next section, as some tests require data to have normal distribution. Thus, we decide to eliminate outliers in this variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735ca1f-1d81-42ae-871a-7576abf55ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_outliers_low_percentatge(df, columns):\n",
    "    cleaned_df = df.copy()\n",
    "    for col in columns:\n",
    "        if col in cleaned_df.columns:\n",
    "            Q1 = cleaned_df[col].quantile(0.25)\n",
    "            Q3 = cleaned_df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "\n",
    "            before = len(cleaned_df)\n",
    "            cleaned_df = cleaned_df[(cleaned_df[col] >= lower) & (cleaned_df[col] <= upper)]\n",
    "            after = len(cleaned_df)\n",
    "\n",
    "            print(f\"{col}: removed {before - after} rows ({((before - after)/before)*100:.2f}%)\")\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe5cff-3842-46b4-acda-ba3c54784072",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_clean = removing_outliers_low_percentatge(observation, low_outlier_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8fa4f-33da-42ff-8b69-2d41867f0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOriginal shape:\", observation.shape)\n",
    "print(\"Cleaned shape:\", observation_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c80359f-eb2a-4b7c-aa0b-81a38bdaa1cf",
   "metadata": {},
   "source": [
    "At this point, with variables whose percentatge of outliers is > 1%, our ide is to use knn to impute them, becuase otherwise we would lose a lot of data and relevant information. However, we'll look at the distributions as well to take a make a final decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0bce2-ea27-426f-acff-189321f6e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_high_outlier_columns = ['CO', 'HR', 'FiO₂', 'latitude']\n",
    "observation_imputed = observation_clean.copy()\n",
    "for column in medium_high_outlier_columns:\n",
    "    data = observation_imputed[column].copy()\n",
    "    outliers = identify_outliers(data)\n",
    "    data_with_nans = data.copy()\n",
    "    data_with_nans[outliers.index] = np.nan\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    imputed_data = imputer.fit_transform(data_with_nans.to_frame())\n",
    "    imputed_series = pd.Series(imputed_data.ravel(), index=data.index)\n",
    "    observation_imputed[column] = imputed_series\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    fig.suptitle(f\"{column} Distribution - Before vs After KNN Imputation\", fontsize=14, fontweight='bold')\n",
    "\n",
    "    sns.histplot(data, bins=30, kde=True, ax=axes[0], color='steelblue')\n",
    "    axes[0].set_title(\"Before Imputation\")\n",
    "    axes[0].set_xlabel(column)\n",
    "    axes[0].set_ylabel(\"\")\n",
    "\n",
    "    sns.histplot(imputed_series, bins=30, kde=True, ax=axes[1], color='seagreen')\n",
    "    axes[1].set_title(\"After Imputation (KNN)\")\n",
    "    axes[1].set_xlabel(column)\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836aee7-5bbf-4810-81b3-4513b805ed63",
   "metadata": {},
   "source": [
    "By looking at the distribution we find beneficial to use knn in two cases out of 4. In the case of CO, doing knn helps us see better its distribution than before. In this case, it is perfect not to delete those rows because we would lose 10% of our samples, In the 'latitude' case, it does not change so much but so we'll use knn. However, in FiO2 and HR cases, we see that lots of values map to a specific bin, which makes the distribution look strange. In this two medium cases we decide to eliminate outliers, in order to let the distribution more similar to a normal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05162b71-4483-481d-96b3-e42076eabfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['HR', 'FiO₂']:\n",
    "    data = observation[column]\n",
    "    data_without_outliers = remove_outliers_iqr(data)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    fig.suptitle(f\"{column} Distribution - Before vs After outliers\", fontsize=14, fontweight='bold')\n",
    "\n",
    "    sns.histplot(data, bins=30, kde=True, ax=axes[0], color='steelblue')\n",
    "    axes[0].set_title(\"Before outliers\")\n",
    "    axes[0].set_xlabel(column)\n",
    "    axes[0].set_ylabel(\"\")\n",
    "\n",
    "    sns.histplot(data_without_outliers, bins=30, kde=True, ax=axes[1], color='seagreen')\n",
    "    axes[1].set_title(\"After outliers\")\n",
    "    axes[1].set_xlabel(column)\n",
    "    axes[1].set_ylabel(\"\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212f299-7c17-41f7-b707-2c9c96f93e3f",
   "metadata": {},
   "source": [
    "We clearly see that it is benefitial for the variables as they become more normal. As a result, we'll eliminate the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ebc426-61ed-4fba-9b95-ed0f9ce74c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices = set()\n",
    "\n",
    "for col in ['HR', 'FiO₂']:\n",
    "    outliers = identify_outliers(observation_clean[col])\n",
    "    outlier_indices.update(outliers.index)\n",
    "\n",
    "observation_clean = observation_imputed.drop(index=outlier_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b20768-83ba-4d8b-b73c-aa44aa8989f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape before:\", observation_imputed.shape)\n",
    "print(\"Shape after:\", observation_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9bb682-ff81-4deb-ba9d-27f36198b43b",
   "metadata": {},
   "source": [
    "### 1.3 Formulation and statistical verification of hypotheses about the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba64fbb-d7e5-485a-8371-51f51917b446",
   "metadata": {},
   "source": [
    "## A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba9d2e-1788-4ffd-9ad2-50c16c17ae2d",
   "metadata": {},
   "source": [
    "We'll do to statistical tests about our data that are related with the target (variable) oximetry. We are interested to solve the following questions:\n",
    "\n",
    "    - Is there a statistically significant difference of FiO2 between states with and    without oximetry? If there is difference, are FiO2 values, higher or lower?\n",
    "    - Is there a statistically significant difference of HR between states with and    without oximetry? If there is difference, are HR values, higher or lower?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59be1e8-bf4a-4d04-bb0c-b6219de49173",
   "metadata": {},
   "source": [
    "### Test1 \n",
    "### Is there a statistically significant difference of FiO2 between states with and    without oximetry?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbfd03-9fb3-467c-8816-4fc04d2add1b",
   "metadata": {},
   "source": [
    "First, let's formulate our hypothesis:\n",
    "\n",
    "**H_o (null hypothesis)**: FiO2 is the same on average in states with and without oximetry\n",
    "\n",
    "**H1 (alternative hypothesis)**: FiO2 is the same on average in states with and without oximetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c7b67-0f9f-4882-9b50-62743b0343a9",
   "metadata": {},
   "source": [
    "Before proceding to do the test, let's see both groups distiribution in the interested variables. Obviusly, the two groups of out study are rows with oximetry (oximetry 0) and without oximetry (oximetry 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e248758-e259-4d2d-a6f9-320b8afaa111",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='oximetry', y='FiO₂', data=observation_clean[(observation_clean.oximetry == 1) | (observation_clean.oximetry == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be338d7f-b9ce-42b9-bf5a-1c64881debd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FiO2oximetry_yes = observation_clean.loc[observation_clean.oximetry == 1, 'FiO₂']\n",
    "FiO2oximetry_no = observation_clean.loc[observation_clean.oximetry == 0, 'FiO₂']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32393f-8723-40b3-8cc2-b054c9fa1d3e",
   "metadata": {},
   "source": [
    "At first sight it seems that both groups distribution on FiO₂ seems pretty similar. However, this is an initial thought and we have to get statistical results in order to reject out hypothesis or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e37f3-841c-4e0f-90fa-3548e1e22c4d",
   "metadata": {},
   "source": [
    "To do the test we can use t-test or Mann-Witeny U test depending if t-test assumptions are satisfied or not. We can use t-test if:\n",
    "\n",
    "    - Both groups have normal distribution\n",
    "    - Groups have equal variances\n",
    "\n",
    "Let's see if our case satisfies the assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed53ed-0fe5-490c-a45a-80485713676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(FiO2oximetry_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8f112-58ed-4bff-9884-0c243891e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(FiO2oximetry_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9dbf3-953e-4c99-9e77-da83236ade20",
   "metadata": {},
   "source": [
    "Looking at the histograms, they seem pretty close to a normal distribution. The group without oximetry has some strange bin values which make us doubt a little bit. However, this perceptions can only be correoborated by the qqplot and shapito test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8af5ac-896c-48b0-b30b-1be8678d7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sm.ProbPlot(FiO2oximetry_yes, fit=True).qqplot(line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bfa4e4-53f6-4642-994f-8f525e5290e9",
   "metadata": {},
   "source": [
    "By looking at the qqplot, we have changed out minds. First group does not seem to follow a normal distribution because it is light tailed: the distribution tails decrease faster and outliers are rare. For this reason, it does not seem to follow a normal distribution. But to conclude this, we have first have to do the Shapiro test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba3791-334a-4733-9749-50f17be38c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(FiO2oximetry_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead1339-c68d-43db-9a23-4d058675df36",
   "metadata": {},
   "source": [
    "P-value of shapiro test is < 0.05, so this confirms the rejection of null hypothesis in the normality test. This means that we can't consider this group as a normal distributed one. In this case, it is not necessary to check the other group normality nor variances, we can proced to do the Man-Witeny U test because assumptions are not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecd26d-9177-4ec9-bd08-3b8192e3f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(FiO2oximetry_yes, FiO2oximetry_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971e3d2-2786-4ecd-bf94-446d854af256",
   "metadata": {},
   "source": [
    "Since p < 0.005 and even p < 0.001, we have strong evidence to reject the null hypothesis. \n",
    "**By rejecting the null hypothesis, we are saying that there is a statistical significant difference of FiO2 between states with oximetry and without oximetry.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6adb7b-e5b1-41eb-94ba-a460c157e420",
   "metadata": {},
   "source": [
    "### FiO2 values are higher or lower in states with oximetry?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b7b6dd-05cc-417f-843c-26c3b4ad0273",
   "metadata": {},
   "source": [
    "We have already proven that there is an statistical difference in groups, ut which group has higher values? Let's calculate means and decide with them values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef8867-0e0c-475b-bfaf-54673e326fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FiO2oximetry_yes_mean, FiO2oximetry_no_mean = FiO2oximetry_yes.mean(), FiO2oximetry_no.mean()\n",
    "print(FiO2oximetry_yes_mean, FiO2oximetry_no_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88be7e-d40c-4a97-b25b-ba26e29ef03d",
   "metadata": {},
   "source": [
    "We can see comparing means that **states without oximetry have higher FiO2 values on average than states with oximetry**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a3cf0-b4e7-4533-b723-4a8f7f62d88e",
   "metadata": {},
   "source": [
    "### Test2 \n",
    "### Is there a statistically significant difference of HR between states with and    without oximetry?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f75f514-d99d-4f5c-9658-913f81f9dbd9",
   "metadata": {},
   "source": [
    "As the other case, let's formulate our hypothesis:\n",
    "\n",
    "**H_o (null hypothesis)**: HR is the same on average in states with and without oximetry\n",
    "\n",
    "**H1 (alternative hypothesis)**: HR is the same on average in states with and without oximetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577a6b7-46bf-43fa-ba1a-a11df46f01ca",
   "metadata": {},
   "source": [
    "Having stated our hypothesis, now we'll follow the same procedure as the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed75d5-3d01-4cc9-b96f-fdec08bd3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='oximetry', y='HR', data=observation_clean[(observation_clean.oximetry == 1) | (observation_clean.oximetry == 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a47a7-1f5f-4ef6-b17e-689c79d60077",
   "metadata": {},
   "source": [
    "In this case, distributions seem to be closer to the same, basing on the previous boxplots. Hoever, let's check assumptions and perform tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0cb90-a70d-4504-8050-301dff139fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HRoximetry_yes = observation_clean.loc[observation_clean.oximetry == 1, 'HR']\n",
    "HRoximetry_no = observation_clean.loc[observation_clean.oximetry == 0, 'HR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a14e91-b1c5-429a-9009-8e462259fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(HRoximetry_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4de345-b15d-4343-a3ac-e17b813ec861",
   "metadata": {},
   "source": [
    "This histogram seems to decrease faster than a normal, we'll see what qqplot and shapiro test say."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f29f0-7982-4b68-ad9a-30c870f74fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(HRoximetry_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ef7af-c609-4951-8402-295defbe058c",
   "metadata": {},
   "source": [
    "This group seems more normal than the other.\n",
    "\n",
    "Let's do qqplot of the first group to clarify things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42134d2d-dabe-4379-83e0-30618b08af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sm.ProbPlot(HRoximetry_yes, fit=True).qqplot(line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d80936-fbf0-4671-ae15-cb8dce08aca0",
   "metadata": {},
   "source": [
    "As it happened in the previous case, this qqplot does not make us thing that the group distribution is the normal. As before, the distribution is light tailed. We'll perform the shapiro test to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928b2ed-6dab-4a7a-9742-3390c58e85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(HRoximetry_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e437c-6e81-4d43-a9bd-2a16fa08e883",
   "metadata": {},
   "source": [
    "Normality test is rejected, so assumptions do not met and we need te perform Man-Witeny U test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f018e1-e34f-415b-bb97-f5abefbe52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(HRoximetry_yes, HRoximetry_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b2ee2d-3ccf-4e82-ad40-b202bbd3a00a",
   "metadata": {},
   "source": [
    "In this case, p-value of the test is > 0.05, se we can't reject the null hypothesis and **this means that there is no statistical signifcant differenece in HR between group with oximetry and without.**\n",
    "As there is no difference, in this case we know that there is not a group with higher values than the others, so the second question is already answered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4cc7f-43f9-466c-9b21-10b61b8e4f72",
   "metadata": {},
   "source": [
    "## B) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597df454-3bc6-45f7-b4cd-51854399198e",
   "metadata": {},
   "source": [
    "Even though we have already performed the statistical tests, we don't know yet how reliable they are. We can know this by calculating its statistical power\n",
    "Let's begin with the first test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013f0aa-861d-41c0-aa99-9746e747b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(x1, x2):\n",
    "    nx1 = len(x1)\n",
    "    nx2 = len(x2)\n",
    "    s = np.sqrt(((nx1-1) * np.std(x1, ddof=1)**2 + (nx2-1) * np.std(x2, ddof=1)**2) / (nx1 + nx2 - 2))\n",
    "    return (np.abs(np.mean(x1) - np.mean(x2))) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ecaee-5a2b-4d85-88a5-8c258eec7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = cohen_d(FiO2oximetry_yes, FiO2oximetry_no)\n",
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5375c-9251-4861-841c-6f70216838eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FiO2oximetry_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe317d-a888-4e3b-bf2c-26d5fe6f38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FiO2oximetry_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31171fb6-d904-4ef1-b942-76f59d719f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = len(FiO2oximetry_no)/len(FiO2oximetry_yes)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd0ffe6-0576-4dad-b7e3-dfc4809e7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_stats.power.tt_ind_solve_power(cd, len(FiO2oximetry_yes), 0.05, None, ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe5128-d49a-47f1-a6ca-5cfbddc443b9",
   "metadata": {},
   "source": [
    "Here we see that we have obtained 1 (100%) statistical power. This means 100% probability to reject Ho when there is an actual differnce. **This means our test is completely reliable and we can be sure that there is a difference in FiO2 values between states with oximetry and states without oximetry.** This makes sense as there is enough data, a good proportion of it and sufficient difference in data.\n",
    "\n",
    "Let's see with the second test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71797b-20ce-48a8-bd60-3b22e1c36529",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_2 = cohen_d(HRoximetry_yes, HRoximetry_no)\n",
    "cd_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb656ad-1a21-4c9b-82ad-e5090a4b5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio2 = len(HRoximetry_no)/len(HRoximetry_yes)\n",
    "ratio2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ced7b-c4a6-4f9f-af8f-becdbd725e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_stats.power.tt_ind_solve_power(cd, len(HRoximetry_yes), 0.05, None, ratio2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832b41d-6a2d-4937-a7d4-fc25abd0a18a",
   "metadata": {},
   "source": [
    "The same happens with the second test: we can rely on our test and be sure that there is not a significant difference in HR between oximetry-yes and oximetry_no groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
